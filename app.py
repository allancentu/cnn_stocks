import streamlit as st
import tensorflow as tf
import numpy as np
from PIL import Image

# Define a arquitetura do modelo
def my_lenet(do_freq=0.3):
    inputs = tf.keras.layers.Input(shape=(128,128,3))

    c1 = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)
    c1 = tf.keras.layers.BatchNormalization()(c1)
    c1 = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(c1)
    s2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(c1)
    s2 = tf.keras.layers.Dropout(do_freq)(s2)

    c3 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(s2)
    c3 = tf.keras.layers.BatchNormalization()(c3)
    c3 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(c3)
    s4 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(c3)
    s4 = tf.keras.layers.Dropout(do_freq)(s4)

    c5 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(s4)
    c5 = tf.keras.layers.BatchNormalization()(c5)
    c5 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(c5)
    s6 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(c5)
    s6 = tf.keras.layers.Dropout(do_freq)(s6)

    flat = tf.keras.layers.Flatten()(s6)
    f7 = tf.keras.layers.Dense(256, activation='relu')(flat)
    f7 = tf.keras.layers.BatchNormalization()(f7)
    f7 = tf.keras.layers.Dropout(do_freq)(f7)
    f8 = tf.keras.layers.Dense(128, activation='relu')(f7)
    f8 = tf.keras.layers.BatchNormalization()(f8)
    f8 = tf.keras.layers.Dropout(do_freq)(f8)
    outputs = tf.keras.layers.Dense(2, activation='softmax')(f8)

    return tf.keras.models.Model(inputs, outputs, name='my_lenet')

st.set_page_config(page_title="Previs√£o de Tend√™ncia de A√ß√µes", page_icon=":chart_with_upwards_trend:", layout="centered")

st.title("üìà Previs√£o de Tend√™ncia de A√ß√µes a partir de Imagens de Gr√°ficos")
# Sidebar navigation
st.sidebar.title("Navega√ß√£o")
page = st.sidebar.radio(
    "Escolha uma p√°gina:",
    ["üè† P√°gina Principal", "üß† Sobre o Modelo CNN"]
)

if page == "üè† P√°gina Principal":
    st.markdown("""
    Bem-vindo! Este aplicativo utiliza um modelo de deep learnning para prever se o pre√ßo de uma a√ß√£o ir√° **subir** ou **cair** com base em uma imagem de gr√°fico enviada.

    **Importante:**  
    - As previs√µes s√£o para o per√≠odo **t+5** (cinco per√≠odos ap√≥s o √∫ltimo per√≠odo mostrado no gr√°fico).
    - O modelo foi treinado exclusivamente para gr√°ficos do tipo **candlestick**, utilizados em **an√°lise gr√°fica**. O uso de outros tipos de gr√°ficos ou imagens pode gerar resultados inesperados.

    **Como funciona:**  
    1. Fa√ßa o upload de uma imagem de gr√°fico candlestick (JPG, PNG ou JPEG).  
    2. A imagem ser√° redimensionada e processada pelo nosso modelo.  
    3. Voc√™ ver√° a previs√£o e uma pr√©via da sua imagem.
    """, unsafe_allow_html=True)

    st.markdown("### Passo 1: Fa√ßa o Upload de um Gr√°fico Candlestick")
    uploaded_file = st.file_uploader(
        "Formatos suportados: JPG, PNG e JPEG.",
        type=["jpg", "png", "jpeg"]
    )

    # Carrega o modelo uma vez
    @st.cache_resource
    def load_model():
        model = my_lenet()
        model.load_weights("best_model.weights.h5")
        return model

    model = load_model()

    if uploaded_file is not None:
        st.markdown("### Passo 2: Pr√©-visualiza√ß√£o e Processamento da Imagem")
        st.caption("""
        Tratamentos aplicados √† imagem:
        - Convers√£o para o formato RGB (cores padr√£o).
        - Redimensionamento para 128x128 pixels para compatibilidade com o modelo.
        - Normaliza√ß√£o dos valores dos pixels (de 0 a 1).
        Esses passos garantem que a imagem esteja no formato ideal para an√°lise pelo modelo de rede neural.
        """)
        original_image = Image.open(uploaded_file).convert("RGB")
        resized_image = original_image.resize((128, 128))
        img_array = np.array(resized_image) / 255.0  # Normaliza os valores dos pixels
        img_batch = np.expand_dims(img_array, axis=0)  # Adiciona dimens√£o de lote

        tab1, tab2 = st.tabs(["üñºÔ∏è Imagem Original", "üîç Imagem Redimensionada (128x128)"])
        with tab1:
            st.image(original_image, caption="Imagem original", width="content")
        with tab2:
            st.image(resized_image, caption="Redimensionada (128x128)", width="content")

        st.markdown("### Passo 3: Resultado da Previs√£o")
        st.caption("Esta previs√£o √© baseada apenas na imagem de gr√°fico candlestick enviada e n√£o constitui recomenda√ß√£o financeira.")
        with st.spinner("Analisando sua imagem..."):
            try:
                preds = model.predict(img_batch)
                pred_class_idx = int(np.argmax(preds, axis=1)[0])
                pred_class = "üìà subir" if pred_class_idx == 1 else "üìâ cair"
                st.success(f"**Previs√£o para t+5:** O modelo prev√™ que o pre√ßo do ativo ir√° **{pred_class}** daqui a cinco per√≠odos.")
                st.caption("Nota: Esta previs√£o √© baseada apenas na imagem de gr√°fico candlestick enviada e n√£o constitui recomenda√ß√£o financeira.")

                # Exibe as probabilidades
                st.markdown("#### Probabilidades da Previs√£o")
                st.write({
                    "Probabilidade de subir (üìà)": float(preds[0][1]),
                    "Probabilidade de cair (üìâ)": float(preds[0][0])
                })
            except Exception as e:
                st.error(f"N√£o foi poss√≠vel carregar o modelo ou realizar a previs√£o: {e}")
                
            st.markdown("---")
            if "show_dialog" not in st.session_state:
                st.session_state.show_dialog = False

            if st.button("Abrir Formul√°rio de Feedback"):
                st.session_state.show_dialog = True

            if st.session_state.show_dialog:
                with st.dialog("Formul√°rio de Feedback"):
                    st.markdown("Ajude-nos a melhorar! Preencha as informa√ß√µes abaixo:")
                    ticker = st.text_input("Ticker do ativo", placeholder="Ex: PETR4")
                    col1, col2 = st.columns(2)
                    with col1:
                        data_inicio = st.date_input("Data inicial do gr√°fico")
                        hora_inicio = st.time_input("Hora inicial do gr√°fico")
                    with col2:
                        data_fim = st.date_input("Data final do gr√°fico")
                        hora_fim = st.time_input("Hora final do gr√°fico")
                    url_fonte = st.text_input("Fonte dos dados (URL)", placeholder="Cole aqui o link da fonte")
                    acerto = st.radio("O modelo acertou a previs√£o?", ["Sim", "N√£o"])
                    email = st.text_input("Seu e-mail (opcional)", placeholder="Para receber novidades do projeto")
                    enviar = st.button("Enviar Feedback", key="enviar_feedback")

                    if enviar:
                        feedback_obj = {
                            "ticker": ticker,
                            "data_inicio": str(data_inicio),
                            "hora_inicio": str(hora_inicio),
                            "data_fim": str(data_fim),
                            "hora_fim": str(hora_fim),
                            "url_fonte": url_fonte,
                            "acerto": acerto,
                            "email": email,
                            "caminho_imagem_original": str(uploaded_file.name),
                            "caminho_imagem_redimensionada": "imagem_redimensionada.png"
                        }
                        st.success("Obrigado pelo seu feedback! Sua resposta foi registrada com sucesso. üòä")
                        st.json(feedback_obj)
                        st.session_state.show_dialog = False
    else:
        st.info("Por favor, fa√ßa o upload de uma imagem de gr√°fico candlestick para come√ßar.")

elif page == "üß† Sobre o Modelo CNN":
    st.header("üß† Sobre o Modelo de Rede Neural Convolucional (CNN)")
    st.markdown("""
    Este aplicativo utiliza uma arquitetura de rede neural convolucional (CNN) inspirada no cl√°ssico **LeNet-5**, por√©m com diversas melhorias modernas, como camadas de normaliza√ß√£o em lote (*Batch Normalization*) e *Dropout* para evitar overfitting.

    ### Por que essa arquitetura?
    - Redes CNN s√£o especialmente eficazes para an√°lise de imagens, pois conseguem extrair padr√µes visuais relevantes.
    - A arquitetura escolhida √© robusta, eficiente e adaptada para gr√°ficos financeiros, permitindo identificar tend√™ncias visuais em gr√°ficos candlestick.

    ### Dados utilizados no treinamento
    - Foram utilizados **64.000 gr√°ficos candlestick** de a√ß√µes listadas na **Nasdaq** e **NYSE**, cobrindo o per√≠odo de **2020 a 2025**.
    - Os dados foram baixados via biblioteca **yfinance** e os gr√°ficos gerados com **mplfinance**.
    - Todo o conjunto de dados foi normalizado para evitar vi√©s e garantir maior precis√£o.

    ### Principais m√©tricas do modelo
    - **Acur√°cia final de teste:** 99,40%
    - **F1 Score:** 0,9936
    - **Erro de omiss√£o para subida:** 0,62%
    - **Erro de comiss√£o para subida:** 0,66%
    - **Erro de omiss√£o para queda:** 0,58%
    - **Erro de comiss√£o para queda:** 0,55%

    Estes resultados indicam que o modelo √© altamente confi√°vel para identificar tend√™ncias de subida ou queda em gr√°ficos candlestick, considerando o horizonte de previs√£o de **t+5** per√≠odos.

    ---
    **Observa√ß√£o:** Apesar da alta precis√£o, este modelo serve apenas como ferramenta de apoio e n√£o substitui an√°lise financeira profissional.
    """)
